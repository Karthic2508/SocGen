{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "\n",
        "# Assuming we have our DataFrame 'df' from the previous example\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate dates for one year of hourly data\n",
        "start_date = datetime(2023, 1, 1)\n",
        "dates = [start_date + timedelta(hours=i) for i in range(8760)]  # 365 days * 24 hours\n",
        "\n",
        "# Create base data\n",
        "data = {\n",
        "    'timestamp': dates,\n",
        "    'network_traffic': np.random.normal(1000, 200, 8760),\n",
        "    'latency': np.random.normal(20, 5, 8760),\n",
        "    'packet_loss': np.random.normal(0.5, 0.2, 8760),\n",
        "    'cpu_usage': np.random.normal(60, 15, 8760),\n",
        "    'memory_usage': np.random.normal(70, 10, 8760),\n",
        "    'trading_volume': np.random.normal(10000, 2000, 8760),\n",
        "    'market_volatility': np.random.normal(15, 5, 8760)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add daily and weekly patterns\n",
        "df['network_traffic'] += np.sin(np.arange(8760) * (2 * np.pi / 24)) * 200  # Daily pattern\n",
        "df['trading_volume'] += np.sin(np.arange(8760) * (2 * np.pi / (24 * 7))) * 3000  # Weekly pattern\n",
        "\n",
        "# Add some random congestion events\n",
        "congestion_events = np.random.choice(8760, size=100, replace=False)\n",
        "df.loc[congestion_events, 'network_traffic'] *= np.random.uniform(1.5, 2.5, 100)\n",
        "df.loc[congestion_events, 'latency'] *= np.random.uniform(1.3, 2.0, 100)\n",
        "df.loc[congestion_events, 'packet_loss'] *= np.random.uniform(1.5, 3.0, 100)\n",
        "\n",
        "# Add some correlated effects\n",
        "df.loc[df['trading_volume'] > df['trading_volume'].quantile(0.95), 'network_traffic'] *= 1.2\n",
        "df.loc[df['cpu_usage'] > 80, 'latency'] *= 1.1\n",
        "\n",
        "# Create congestion_event column\n",
        "df['congestion_event'] = 0\n",
        "df.loc[(df['network_traffic'] > df['network_traffic'].quantile(0.95)) &\n",
        "       (df['latency'] > df['latency'].quantile(0.95)) &\n",
        "       (df['packet_loss'] > df['packet_loss'].quantile(0.95)), 'congestion_event'] = 1\n",
        "\n",
        "# Ensure non-negative values\n",
        "for col in ['network_traffic', 'latency', 'packet_loss', 'cpu_usage', 'memory_usage', 'trading_volume', 'market_volatility']:\n",
        "    df[col] = df[col].clip(lower=0)\n",
        "\n",
        "# Display basic statistics and first few rows\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Number of congestion events: {df['congestion_event'].sum()}\")\n",
        "\n",
        "# Save to CSV (optional)\n",
        "df.to_csv('network_data.csv', index=False)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "rZ7q9Xq8kFwx",
        "outputId": "1b6c041e-d1fd-424a-c573-fddc6ef3d89a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset shape: (8760, 9)\n",
            "Number of congestion events: 40\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            timestamp  network_traffic    latency  packet_loss  cpu_usage  \\\n",
              "0 2023-01-01 00:00:00      1099.342831  24.857062     0.524070  76.209318   \n",
              "1 2023-01-01 01:00:00      1024.110949  13.523707     0.644091  71.681097   \n",
              "2 2023-01-01 02:00:00      1229.537708  14.062234     0.328283  66.577592   \n",
              "3 2023-01-01 03:00:00      1446.027328  22.894549     0.839103  69.568291   \n",
              "4 2023-01-01 04:00:00      1126.374406  19.678312     0.090567  62.702585   \n",
              "\n",
              "   memory_usage  trading_volume  market_volatility  congestion_event  \n",
              "0     66.188741    12272.132384          16.834907                 0  \n",
              "1     76.880177    11414.984879          15.522807                 0  \n",
              "2     56.918259     9382.709891           8.767731                 0  \n",
              "3     58.507044    11941.551252          21.735282                 0  \n",
              "4     67.015647    14610.942936          11.285495                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8a57f19-a611-4617-a6b5-a00952e5b2f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>network_traffic</th>\n",
              "      <th>latency</th>\n",
              "      <th>packet_loss</th>\n",
              "      <th>cpu_usage</th>\n",
              "      <th>memory_usage</th>\n",
              "      <th>trading_volume</th>\n",
              "      <th>market_volatility</th>\n",
              "      <th>congestion_event</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-01 00:00:00</td>\n",
              "      <td>1099.342831</td>\n",
              "      <td>24.857062</td>\n",
              "      <td>0.524070</td>\n",
              "      <td>76.209318</td>\n",
              "      <td>66.188741</td>\n",
              "      <td>12272.132384</td>\n",
              "      <td>16.834907</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-01 01:00:00</td>\n",
              "      <td>1024.110949</td>\n",
              "      <td>13.523707</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>71.681097</td>\n",
              "      <td>76.880177</td>\n",
              "      <td>11414.984879</td>\n",
              "      <td>15.522807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-01 02:00:00</td>\n",
              "      <td>1229.537708</td>\n",
              "      <td>14.062234</td>\n",
              "      <td>0.328283</td>\n",
              "      <td>66.577592</td>\n",
              "      <td>56.918259</td>\n",
              "      <td>9382.709891</td>\n",
              "      <td>8.767731</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-01 03:00:00</td>\n",
              "      <td>1446.027328</td>\n",
              "      <td>22.894549</td>\n",
              "      <td>0.839103</td>\n",
              "      <td>69.568291</td>\n",
              "      <td>58.507044</td>\n",
              "      <td>11941.551252</td>\n",
              "      <td>21.735282</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-01 04:00:00</td>\n",
              "      <td>1126.374406</td>\n",
              "      <td>19.678312</td>\n",
              "      <td>0.090567</td>\n",
              "      <td>62.702585</td>\n",
              "      <td>67.015647</td>\n",
              "      <td>14610.942936</td>\n",
              "      <td>11.285495</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8a57f19-a611-4617-a6b5-a00952e5b2f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8a57f19-a611-4617-a6b5-a00952e5b2f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8a57f19-a611-4617-a6b5-a00952e5b2f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a8463a5-7693-476a-bce7-f8212ea9bef0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a8463a5-7693-476a-bce7-f8212ea9bef0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a8463a5-7693-476a-bce7-f8212ea9bef0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8760,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-01 00:00:00\",\n        \"max\": \"2023-12-31 23:00:00\",\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          \"2023-09-10 08:00:00\",\n          \"2023-08-20 12:00:00\",\n          \"2023-09-07 14:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"network_traffic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 279.4637257218469,\n        \"min\": 59.46380955125508,\n        \"max\": 4025.659572862555,\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          1188.1069995222558,\n          1015.1152745340281,\n          1007.5536380737196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.334870339294926,\n        \"min\": 0.3879987419082873,\n        \"max\": 57.492507408221755,\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          10.692433196703998,\n          24.123508703930487,\n          25.814512862720697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"packet_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21280256766840436,\n        \"min\": 0.0,\n        \"max\": 2.513311290618982,\n        \"num_unique_values\": 8712,\n        \"samples\": [\n          0.35554918552074066,\n          0.5335300310773312,\n          0.8641160536529933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_usage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.225042532019264,\n        \"min\": 0.0,\n        \"max\": 115.91750017144781,\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          57.19787185660471,\n          47.54884951179598,\n          70.01089732006217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"memory_usage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.953893582778372,\n        \"min\": 27.046090159319945,\n        \"max\": 105.36531654873366,\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          78.5597269679443,\n          64.27431610336599,\n          54.202734828669364\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trading_volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2888.8868228202787,\n        \"min\": 398.87087874692907,\n        \"max\": 18639.31650087813,\n        \"num_unique_values\": 8760,\n        \"samples\": [\n          9997.547078508076,\n          12483.907101263243,\n          7301.006029693304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"market_volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.081652900633417,\n        \"min\": 0.0,\n        \"max\": 33.726896139879145,\n        \"num_unique_values\": 8742,\n        \"samples\": [\n          24.45430199053314,\n          15.286207649304346,\n          19.12774151567341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"congestion_event\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Ensure congestion_event is of integer type\n",
        "df['congestion_event'] = df['congestion_event'].astype(int)\n",
        "\n",
        "# Data Preparation\n",
        "def create_sequences(data, sequence_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data[i:(i + sequence_length)])\n",
        "        y.append(data[i + sequence_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare features and target\n",
        "features = ['network_traffic', 'latency', 'packet_loss', 'cpu_usage', 'memory_usage', 'trading_volume', 'market_volatility']\n",
        "X = df[features].values\n",
        "y_congestion = df['congestion_event'].values  # This should now be integers (0 or 1)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 24  # Use 24 hours of data to predict the next hour\n",
        "X_seq, y_seq = create_sequences(X, sequence_length)\n",
        "y_congestion_seq = y_seq[:, -1]  # We only need the congestion_event for the target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_congestion_train, y_congestion_test = train_test_split(X_seq, y_congestion_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure y_congestion_train and y_congestion_test are integers\n",
        "y_congestion_train = y_congestion_train.astype(int)\n",
        "y_congestion_test = y_congestion_test.astype(int)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "\n",
        "# Network Traffic Prediction Model (LSTM)\n",
        "def create_traffic_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, activation='relu', input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "traffic_model = create_traffic_model((sequence_length, X_train.shape[-1]))\n",
        "traffic_model.fit(X_train_scaled, X_train[:, -1, 0], epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Predict traffic for training and test data\n",
        "X_train_traffic_pred = traffic_model.predict(X_train_scaled)\n",
        "X_test_traffic_pred = traffic_model.predict(X_test_scaled)\n",
        "\n",
        "# Prepare data for congestion model (replace actual traffic with predicted traffic)\n",
        "X_train_with_pred = X_train_scaled.copy()\n",
        "X_test_with_pred = X_test_scaled.copy()\n",
        "\n",
        "X_train_with_pred[:, -1, 0] = X_train_traffic_pred.flatten()\n",
        "X_test_with_pred[:, -1, 0] = X_test_traffic_pred.flatten()\n",
        "\n",
        "# Congestion Prediction Model (Random Forest)\n",
        "def create_congestion_model():\n",
        "    return RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "congestion_model = create_congestion_model()\n",
        "congestion_model.fit(X_train_with_pred[:, -1, :], y_congestion_train)\n",
        "\n",
        "# Evaluate congestion prediction model\n",
        "congestion_pred = congestion_model.predict(X_test_with_pred[:, -1, :])\n",
        "print(\"\\nCongestion Prediction Performance:\")\n",
        "print(classification_report(y_congestion_test, congestion_pred))\n",
        "print(confusion_matrix(y_congestion_test, congestion_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D3O4HVylM9q",
        "outputId": "fd700bdf-5945-4639-b251-ce3d31bf8569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 2s 8ms/step\n",
            "55/55 [==============================] - 1s 11ms/step\n",
            "\n",
            "Congestion Prediction Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.00      0.00      0.00        12\n",
            "           5       0.00      0.00      0.00        21\n",
            "           6       0.00      0.00      0.00        42\n",
            "           7       0.00      0.00      0.00        36\n",
            "           8       0.07      0.03      0.04        67\n",
            "           9       0.03      0.01      0.02        68\n",
            "          10       0.03      0.03      0.03       102\n",
            "          11       0.04      0.05      0.04       109\n",
            "          12       0.09      0.12      0.10       129\n",
            "          13       0.06      0.09      0.07       139\n",
            "          14       0.09      0.15      0.11       118\n",
            "          15       0.09      0.11      0.10       148\n",
            "          16       0.06      0.09      0.07       127\n",
            "          17       0.03      0.04      0.04       113\n",
            "          18       0.03      0.04      0.03       111\n",
            "          19       0.05      0.04      0.04       104\n",
            "          20       0.02      0.02      0.02        65\n",
            "          21       0.11      0.03      0.05        60\n",
            "          22       0.17      0.02      0.04        43\n",
            "          23       0.00      0.00      0.00        30\n",
            "          24       0.00      0.00      0.00        22\n",
            "          25       0.00      0.00      0.00        20\n",
            "          26       0.00      0.00      0.00        10\n",
            "          27       0.00      0.00      0.00         9\n",
            "          28       0.00      0.00      0.00         5\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.06      1748\n",
            "   macro avg       0.03      0.03      0.03      1748\n",
            "weighted avg       0.05      0.06      0.05      1748\n",
            "\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  1  0  1  0  1  1  0  0  1  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  1  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  1  0  0  2  3  0  1  1  2  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  1  1  0  2  2  0  2  1  1  1  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  3  3  0  2  0  2  0  1  1  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  3  3  2  2  0  1  2  3  1  2  1  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  3  0  6  0  3  6  5  7  2  4  3  3  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  5  2  3  2  1  5  4  1  6  2  2  0  2  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  2  4  6  4 11 10  8  4  3  7  2  2  2  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  1  0  0  1  5  3 13  5  4  5  9  4  8  6  2  0  0  0\n",
            "   0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  1  2  3  3 11 11 14 13 11  8 10  6  3  5  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  1  3  5 11 17 18 17 16  7  4  5  3  1  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  1  3  4  6  5 16 17 11 12 13 15  7 11  6  0  0  0\n",
            "   1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  1  1  2  1  9 10 15 13 14 12 15 12 17  6  6  3  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  7 13 10 20 18  9 11 12  7  5  2  2  1  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  1  0  2 10 13 18 21 19 17 10  9 12  9  5  1  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  1  0  1  0 13  9 12 18 13 17 11 12  5  5  5  2  1  0\n",
            "   0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  1  0  0  0  4  2  5 11 11 13 10 17 17  5  6  5  4  1  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  4  5  6 12 13 11 16  9 11 11  4  2  2  2  1  0\n",
            "   0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  2  3  3  3  7  8 12 12 12 12 10  8  5  4  2  1  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  2  4  2  6  4 10 12  1 10  7  3  1  1  1  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  1  0  2  7  7  8  6 10  7  4  2  2  2  0  1\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  4  2  5  7  7  5  4  3  4  1  0  0  1  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  1  1  2  3  2  2  5  4  2  3  2  1  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  1  1  0  2  4  3  4  2  3  1  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  3  2  0  2  1  3  4  4  1  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  2  2  2  0  0  2  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  1  2  2  0  1  0  1  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  2  0  1  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  1  1  0  0  0  0  1  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnuSb4bxj_wu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Prediction and Mitigation Functions\n",
        "def predict_traffic_and_congestion(traffic_model, congestion_model, scaler, current_data):\n",
        "    \"\"\"\n",
        "    Predict network traffic and then use it to predict congestion probability.\n",
        "    \"\"\"\n",
        "    scaled_data = scaler.transform(current_data.reshape(-1, current_data.shape[-1])).reshape(current_data.shape)\n",
        "\n",
        "    # Predict traffic\n",
        "    traffic_pred = traffic_model.predict(scaled_data)[0][0]\n",
        "\n",
        "    # Replace actual traffic with predicted traffic\n",
        "    scaled_data_with_pred = scaled_data.copy()\n",
        "    scaled_data_with_pred[0, -1, 0] = traffic_pred\n",
        "\n",
        "    # Predict congestion\n",
        "    congestion_prob = congestion_model.predict_proba(scaled_data_with_pred[0, -1, :].reshape(1, -1))[0][1]\n",
        "\n",
        "    return traffic_pred, congestion_prob\n",
        "\n",
        "def mitigate_congestion(traffic_pred, congestion_prob, threshold=0.0):\n",
        "    \"\"\"\n",
        "    Implement mitigation strategies based on predicted traffic and congestion probability.\n",
        "    \"\"\"\n",
        "    print(f\"Predicted Network Traffic: {traffic_pred:.2f}\")\n",
        "    print(f\"Congestion Probability: {congestion_prob:.4f}\")\n",
        "\n",
        "    if congestion_prob > threshold:\n",
        "        print(\"High risk of congestion detected. Implementing mitigation strategies:\")\n",
        "        print(\"1. Rerouting network traffic\")\n",
        "        print(\"2. Adjusting network configurations\")\n",
        "        print(\"3. Scaling up resources\")\n",
        "\n",
        "        if congestion_prob > 0.9:\n",
        "            print(\"4. Activating emergency backup systems\")\n",
        "            print(\"5. Notifying IT team for immediate intervention\")\n",
        "    else:\n",
        "        print(\"Low risk of congestion. Maintaining normal operations.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Test Case\n",
        "np.random.seed(42)\n",
        "test_case = pd.DataFrame({\n",
        "    'network_traffic': np.random.normal(1000, 200, 48),\n",
        "    'latency': np.random.normal(20, 5, 48),\n",
        "    'packet_loss': np.random.normal(0.5, 0.2, 48),\n",
        "    'cpu_usage': np.random.normal(60, 15, 48),\n",
        "    'memory_usage': np.random.normal(70, 10, 48),\n",
        "    'trading_volume': np.random.normal(10000, 2000, 48),\n",
        "    'market_volatility': np.random.normal(15, 5, 48)\n",
        "})\n",
        "\n",
        "# Add some patterns to make it more realistic\n",
        "test_case['network_traffic'] += np.sin(np.arange(48) * (2 * np.pi / 24)) * 200  # Daily pattern\n",
        "test_case['trading_volume'] += np.sin(np.arange(48) * (2 * np.pi / 24)) * 3000  # Daily pattern\n",
        "\n",
        "# Simulate a spike in network traffic and trading volume\n",
        "test_case.loc[30:35, 'network_traffic'] *= 2\n",
        "test_case.loc[30:35, 'trading_volume'] *= 1.5\n",
        "test_case.loc[30:35, 'latency'] *= 1.5\n",
        "test_case.loc[30:35, 'packet_loss'] *= 2\n",
        "\n",
        "# Ensure non-negative values\n",
        "for col in test_case.columns:\n",
        "    test_case[col] = test_case[col].clip(lower=0)\n",
        "\n",
        "# Prepare the test data\n",
        "X_test = test_case.values\n",
        "X_test_seq = np.array([X_test[i:i+sequence_length] for i in range(24)])\n",
        "\n"
      ],
      "metadata": {
        "id": "etwsB66tkasR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print network status\n",
        "def print_network_status(hour, data):\n",
        "    print(f\"Hour {hour + 1} Network Status:\")\n",
        "    print(f\"  Actual Network Traffic: {data[hour, -1, 0]:.2f}\")\n",
        "    print(f\"  Latency: {data[hour, -1, 1]:.2f}\")\n",
        "    print(f\"  Packet Loss: {data[hour, -1, 2]:.2f}\")\n",
        "    print(f\"  CPU Usage: {data[hour, -1, 3]:.2f}\")\n",
        "    print(f\"  Memory Usage: {data[hour, -1, 4]:.2f}\")\n",
        "    print(f\"  Trading Volume: {data[hour, -1, 5]:.2f}\")\n",
        "    print(f\"  Market Volatility: {data[hour, -1, 6]:.2f}\")\n",
        "\n",
        "# Run the test case\n",
        "for i in range(24):\n",
        "    current_data = X_test_seq[i:i+1]\n",
        "    traffic_pred, congestion_prob = predict_traffic_and_congestion(traffic_model, congestion_model, scaler, current_data)\n",
        "\n",
        "    print_network_status(i, X_test_seq)\n",
        "    mitigate_congestion(traffic_pred, congestion_prob)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTDj9ovTkNz3",
        "outputId": "68095c45-473b-4ce3-b4f4-5bff8b2bf1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Hour 1 Network Status:\n",
            "  Actual Network Traffic: 663.29\n",
            "  Latency: 27.69\n",
            "  Packet Loss: 0.65\n",
            "  CPU Usage: 88.45\n",
            "  Memory Usage: 77.59\n",
            "  Trading Volume: 7174.77\n",
            "  Market Volatility: 20.49\n",
            "Predicted Network Traffic: 768.42\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Hour 2 Network Status:\n",
            "  Actual Network Traffic: 891.12\n",
            "  Latency: 19.82\n",
            "  Packet Loss: 0.66\n",
            "  CPU Usage: 56.32\n",
            "  Memory Usage: 62.27\n",
            "  Trading Volume: 9494.86\n",
            "  Market Volatility: 19.13\n",
            "Predicted Network Traffic: 958.93\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Hour 3 Network Status:\n",
            "  Actual Network Traffic: 1073.95\n",
            "  Latency: 27.82\n",
            "  Packet Loss: 0.32\n",
            "  CPU Usage: 48.69\n",
            "  Memory Usage: 67.63\n",
            "  Trading Volume: 8280.89\n",
            "  Market Volatility: 19.07\n",
            "Predicted Network Traffic: 1106.91\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Hour 4 Network Status:\n",
            "  Actual Network Traffic: 869.80\n",
            "  Latency: 6.90\n",
            "  Packet Loss: 0.78\n",
            "  CPU Usage: 46.66\n",
            "  Memory Usage: 65.15\n",
            "  Trading Volume: 14764.82\n",
            "  Market Volatility: 21.53\n",
            "Predicted Network Traffic: 1022.97\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Hour 5 Network Status:\n",
            "  Actual Network Traffic: 1216.56\n",
            "  Latency: 24.11\n",
            "  Packet Loss: 0.22\n",
            "  CPU Usage: 47.76\n",
            "  Memory Usage: 70.82\n",
            "  Trading Volume: 9261.04\n",
            "  Market Volatility: 15.11\n",
            "Predicted Network Traffic: 1225.60\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Hour 6 Network Status:\n",
            "  Actual Network Traffic: 1053.08\n",
            "  Latency: 20.44\n",
            "  Packet Loss: 0.62\n",
            "  CPU Usage: 58.84\n",
            "  Memory Usage: 93.15\n",
            "  Trading Volume: 11717.99\n",
            "  Market Volatility: 18.41\n",
            "Predicted Network Traffic: 1142.00\n",
            "Congestion Probability: 0.0100\n",
            "High risk of congestion detected. Implementing mitigation strategies:\n",
            "1. Rerouting network traffic\n",
            "2. Adjusting network configurations\n",
            "3. Scaling up resources\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Hour 7 Network Status:\n",
            "  Actual Network Traffic: 1134.85\n",
            "  Latency: 18.50\n",
            "  Packet Loss: 0.94\n",
            "  CPU Usage: 65.12\n",
            "  Memory Usage: 51.33\n",
            "  Trading Volume: 13159.26\n",
            "  Market Volatility: 13.45\n",
            "Predicted Network Traffic: 1168.54\n",
            "Congestion Probability: 0.0100\n",
            "High risk of congestion detected. Implementing mitigation strategies:\n",
            "1. Rerouting network traffic\n",
            "2. Adjusting network configurations\n",
            "3. Scaling up resources\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Hour 8 Network Status:\n",
            "  Actual Network Traffic: 2159.32\n",
            "  Latency: 30.69\n",
            "  Packet Loss: 0.60\n",
            "  CPU Usage: 64.15\n",
            "  Memory Usage: 76.86\n",
            "  Trading Volume: 23823.82\n",
            "  Market Volatility: 16.62\n",
            "Predicted Network Traffic: 2004.22\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Hour 9 Network Status:\n",
            "  Actual Network Traffic: 3127.28\n",
            "  Latency: 15.09\n",
            "  Packet Loss: 0.77\n",
            "  CPU Usage: 72.41\n",
            "  Memory Usage: 53.87\n",
            "  Trading Volume: 15039.08\n",
            "  Market Volatility: 14.35\n",
            "Predicted Network Traffic: 2473.17\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Hour 10 Network Status:\n",
            "  Actual Network Traffic: 2341.01\n",
            "  Latency: 28.35\n",
            "  Packet Loss: 1.04\n",
            "  CPU Usage: 60.20\n",
            "  Memory Usage: 65.28\n",
            "  Trading Volume: 22386.61\n",
            "  Market Volatility: 15.48\n",
            "Predicted Network Traffic: 1993.51\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Hour 11 Network Status:\n",
            "  Actual Network Traffic: 1859.76\n",
            "  Latency: 32.68\n",
            "  Packet Loss: 0.80\n",
            "  CPU Usage: 81.80\n",
            "  Memory Usage: 80.89\n",
            "  Trading Volume: 18212.68\n",
            "  Market Volatility: 17.98\n",
            "Predicted Network Traffic: 1441.34\n",
            "Congestion Probability: 0.0100\n",
            "High risk of congestion detected. Implementing mitigation strategies:\n",
            "1. Rerouting network traffic\n",
            "2. Adjusting network configurations\n",
            "3. Scaling up resources\n",
            "\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Hour 12 Network Status:\n",
            "  Actual Network Traffic: 2529.02\n",
            "  Latency: 41.08\n",
            "  Packet Loss: 0.38\n",
            "  CPU Usage: 56.03\n",
            "  Memory Usage: 70.64\n",
            "  Trading Volume: 14305.47\n",
            "  Market Volatility: 10.91\n",
            "Predicted Network Traffic: 2585.82\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Hour 13 Network Status:\n",
            "  Actual Network Traffic: 1615.19\n",
            "  Latency: 26.11\n",
            "  Packet Loss: 1.03\n",
            "  CPU Usage: 100.80\n",
            "  Memory Usage: 59.22\n",
            "  Trading Volume: 17551.00\n",
            "  Market Volatility: 25.46\n",
            "Predicted Network Traffic: 1035.18\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Hour 14 Network Status:\n",
            "  Actual Network Traffic: 1041.77\n",
            "  Latency: 15.96\n",
            "  Packet Loss: 0.29\n",
            "  CPU Usage: 69.39\n",
            "  Memory Usage: 62.85\n",
            "  Trading Volume: 10398.12\n",
            "  Market Volatility: 9.97\n",
            "Predicted Network Traffic: 949.54\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Hour 15 Network Status:\n",
            "  Actual Network Traffic: 556.30\n",
            "  Latency: 17.49\n",
            "  Packet Loss: 0.59\n",
            "  CPU Usage: 47.14\n",
            "  Memory Usage: 76.80\n",
            "  Trading Volume: 8023.11\n",
            "  Market Volatility: 8.93\n",
            "Predicted Network Traffic: 715.99\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Hour 16 Network Status:\n",
            "  Actual Network Traffic: 634.36\n",
            "  Latency: 24.58\n",
            "  Packet Loss: 0.32\n",
            "  CPU Usage: 43.94\n",
            "  Memory Usage: 62.70\n",
            "  Trading Volume: 8639.60\n",
            "  Market Volatility: 20.79\n",
            "Predicted Network Traffic: 796.03\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Hour 17 Network Status:\n",
            "  Actual Network Traffic: 897.95\n",
            "  Latency: 21.64\n",
            "  Packet Loss: 0.81\n",
            "  CPU Usage: 67.24\n",
            "  Memory Usage: 72.16\n",
            "  Trading Volume: 7108.05\n",
            "  Market Volatility: 18.96\n",
            "Predicted Network Traffic: 918.42\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Hour 18 Network Status:\n",
            "  Actual Network Traffic: 974.49\n",
            "  Latency: 17.35\n",
            "  Packet Loss: 0.34\n",
            "  CPU Usage: 56.65\n",
            "  Memory Usage: 70.46\n",
            "  Trading Volume: 7628.96\n",
            "  Market Volatility: 18.12\n",
            "Predicted Network Traffic: 980.20\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Hour 19 Network Status:\n",
            "  Actual Network Traffic: 841.09\n",
            "  Latency: 22.57\n",
            "  Packet Loss: 0.44\n",
            "  CPU Usage: 70.71\n",
            "  Memory Usage: 63.48\n",
            "  Trading Volume: 8426.48\n",
            "  Market Volatility: 18.14\n",
            "Predicted Network Traffic: 836.31\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Hour 20 Network Status:\n",
            "  Actual Network Traffic: 776.87\n",
            "  Latency: 20.49\n",
            "  Packet Loss: 0.66\n",
            "  CPU Usage: 67.10\n",
            "  Memory Usage: 91.44\n",
            "  Trading Volume: 10172.03\n",
            "  Market Volatility: 14.94\n",
            "Predicted Network Traffic: 814.39\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Hour 21 Network Status:\n",
            "  Actual Network Traffic: 746.59\n",
            "  Latency: 24.84\n",
            "  Packet Loss: 0.25\n",
            "  CPU Usage: 58.91\n",
            "  Memory Usage: 76.34\n",
            "  Trading Volume: 4626.59\n",
            "  Market Volatility: 10.51\n",
            "Predicted Network Traffic: 805.39\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Hour 22 Network Status:\n",
            "  Actual Network Traffic: 531.09\n",
            "  Latency: 16.49\n",
            "  Packet Loss: 0.55\n",
            "  CPU Usage: 47.30\n",
            "  Memory Usage: 49.75\n",
            "  Trading Volume: 11667.99\n",
            "  Market Volatility: 15.38\n",
            "Predicted Network Traffic: 605.63\n",
            "Congestion Probability: 0.0200\n",
            "High risk of congestion detected. Implementing mitigation strategies:\n",
            "1. Rerouting network traffic\n",
            "2. Adjusting network configurations\n",
            "3. Scaling up resources\n",
            "\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Hour 23 Network Status:\n",
            "  Actual Network Traffic: 714.61\n",
            "  Latency: 18.36\n",
            "  Packet Loss: 0.76\n",
            "  CPU Usage: 37.28\n",
            "  Memory Usage: 71.86\n",
            "  Trading Volume: 3974.50\n",
            "  Market Volatility: 11.61\n",
            "Predicted Network Traffic: 781.86\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Hour 24 Network Status:\n",
            "  Actual Network Traffic: 807.87\n",
            "  Latency: 18.04\n",
            "  Packet Loss: 0.18\n",
            "  CPU Usage: 53.30\n",
            "  Memory Usage: 63.38\n",
            "  Trading Volume: 8196.43\n",
            "  Market Volatility: 19.88\n",
            "Predicted Network Traffic: 870.62\n",
            "Congestion Probability: 0.0000\n",
            "Low risk of congestion. Maintaining normal operations.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}